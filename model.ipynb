{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1L, 3L, 64L, 64L)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os;\n",
    "import six.moves.cPickle as pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import PIL.Image as Im\n",
    "import keras\n",
    "import theano\n",
    "import matplotlib.pyplot as plt\n",
    "# reading dataset\n",
    "\n",
    "mscoco= r\"C:\\Users\\NAVPREET\\AnacondaProjects\\inpainting\\inpainting\"\n",
    "split=\"train2014\"\n",
    "path_to_dataset= os.path.join(mscoco, split)\n",
    "\n",
    "cap= \"dict_key_imgID_value_caps_train_and_valid.pkl\"\n",
    "path_to_captions= os.path.join(mscoco, cap)\n",
    "\n",
    "images= glob.glob(path_to_dataset+\"/*jpg\")\n",
    "theano.config.floatX = 'float32'\n",
    "\n",
    "\n",
    "# Getting a minibatch of data\n",
    "def minibatch_of_data(batch_index,batch_size,mscoco= r\"C:\\Users\\NAVPREET\\AnacondaProjects\\inpainting\\inpainting\", split=\"train2014\"):\n",
    "    im_batch=images[batch_size*batch_index: batch_index+1*batch_size]\n",
    "    b_input=[]\n",
    "    b_target=[]\n",
    "    im_arr=[]\n",
    "    for i, path in enumerate(im_batch):\n",
    "        Image=Im.open(path)\n",
    "        im_arr = np.array(Image)\n",
    "        \n",
    "        # get the central part of image and set all values in that part to 0\n",
    "        \n",
    "        centre_of_image= (int(np.floor(im_arr.shape[0] / 2.)), int(np.floor(im_arr.shape[1] / 2.)))\n",
    "        \n",
    "        # setting central part of image to 0\n",
    "        \n",
    "        if len(im_arr==3):\n",
    "            # ignoring gray scale images\n",
    "            input= np.copy(im_arr)\n",
    "            # editing centre on image\n",
    "            input[centre_of_image[0]-16:centre_of_image[0]+16,centre_of_image[1]-16:centre_of_image[1]+16]=0\n",
    "            target= im_arr[centre_of_image[0]-16:centre_of_image[0]+16,centre_of_image[1]-16:centre_of_image[1]+16]\n",
    "            b_input.append(np.array(input).transpose(2,0,1).reshape(3,64,64))\n",
    "            b_target.append(np.array(target).transpose(2,0,1).reshape(3,32,32))\n",
    "            # normalized data\n",
    "        return np.array(b_input)/255, np.array(b_target)/255\n",
    "        \n",
    "def datasetsz(mscoco=r\"C:\\Users\\NAVPREET\\AnacondaProjects\\inpainting\\inpainting\", split=\"train2014\"):\n",
    "    data_path = os.path.join(mscoco, split)\n",
    "    return len(glob.glob(data_path + \"/*.jpg\"))\n",
    "        \n",
    "def loaddata(mscoco=r\"C:\\Users\\NAVPREET\\AnacondaProjects\\inpainting\\inpainting\"):\n",
    "    X_train, y_train= minibatch_of_data(0, datasetsz(mscoco= r\"C:\\Users\\NAVPREET\\AnacondaProjects\\inpainting\\inpainting\", split=\"train2014\"))\n",
    "    X_val, y_val= minibatch_of_data(0, datasetsz(mscoco=r\"C:\\Users\\NAVPREET\\AnacondaProjects\\inpainting\\inpainting\", split=\"val2014\"))\n",
    "    return X_train, y_train,X_val, y_val\n",
    "\n",
    "\n",
    "\n",
    "def saveImages(images, path='../results'):\n",
    "    for i, img in enumerate(images):\n",
    "        save_dir = path + '/result_'+str(i)+'.jpg'\n",
    "\n",
    "        img = Im.fromarray(img.astype('uint8'))\n",
    "        img.save(save_dir)\n",
    "\n",
    "X_train, y_train, X_val, y_val=loaddata()\n",
    "print(X_train.shape)\n",
    "\n",
    "\n",
    "def getimage(inner, outer):\n",
    "    \n",
    "    #getting images back in original scale\n",
    "    inner, outer=inner*255, outer*255\n",
    "    outer= outer.tanspose(0,2,3,1).reshape(len(outer), 64, 64, 3)\n",
    "    iner=inner.transpose(0, 2, 3, 1). reshape(len(inner), 32, 32, 3)\n",
    "    \n",
    "    Im_batch=[]\n",
    "    for i, img in enumerate(outer):\n",
    "        centre= (int(np.floor(outer.shape[1]/2.)), int(np.floor(outer.shape[2]/2.)))\n",
    "        rebuilt_image= np.copy(img)\n",
    "        rebuilt_image[centre[0]-16: centre[0]+16, centre[1]-16: centre[1]+16]=inner[1,:,:,:]\n",
    "        Im_batch.img.append(rebuilt_image)\n",
    "    return np.array(Im_batch)\n",
    "\n",
    "\n",
    "\n",
    "def draw_image(input, target, pred):\n",
    "    \"\"\" Draws the true image and the predicted image \"\"\"\n",
    "    # dimshuffle to put channels in last dim so we can plot (x, y, channel)\n",
    "    input = input.transpose((1, 2, 0))\n",
    "    target = target.transpose((1, 2, 0))\n",
    "    pred = pred.transpose((1, 2, 0))\n",
    "\n",
    "    print(input.shape)\n",
    "    # Place the center back of the true image\n",
    "    center = (int(np.floor(input.shape[0] / 2.)), int(np.floor(input.shape[1] / 2.)))\n",
    "\n",
    "    print(center)\n",
    "    input[center[0] - 16:center[0] + 16, center[1] - 16:center[1] + 16, :] = target\n",
    "\n",
    "    # Draw the target\n",
    "    plt.figure(figsize=(8,8)).canvas.set_window_title(\"Target\")\n",
    "    plt.imshow(input)\n",
    "\n",
    "    # Place the center back of the predicted image\n",
    "    # Draw the prediction\n",
    "    input[center[0] - 16:center[0] + 16, center[1] - 16:center[1] + 16, :] = pred\n",
    "    plt.figure(figsize=(8,8)).canvas.set_window_title(\"Prediction\")\n",
    "    plt.imshow(input)\n",
    "\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Convolution2D, Dropout, MaxPooling2D, Deconvolution2D, UpSampling2D, Reshape, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model, Model\n",
    "import scipy as sp\n",
    "\n",
    "# defining hyperparameters of model\n",
    "nb_epoch=10\n",
    "CPname=None\n",
    "\n",
    "for j in range(nb_epoch,-1,-1):\n",
    "    epochStr = str(j)\n",
    "    #runStr = str(i)\n",
    "\n",
    "    if len(epochStr)==1:\n",
    "        epochStr=str(0)+epochStr\n",
    "\n",
    "    if os.path.exists('CP/cnn/cnn-'+epochStr+'.h5'):\n",
    "        CPName='CP/cnn/cnn-'+epochStr+'.h5'\n",
    "        epoch=j+1\n",
    "        #run=i+1\n",
    "        found = True\n",
    "        break\n",
    "#if found:\n",
    "    #break\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "model=Sequential()\n",
    "nb_epoch=1\n",
    "batch_size=128\n",
    "nb_filters=10\n",
    "nb_pool=2\n",
    "nb_conv=2\n",
    "sgd=SGD(lr=0.2, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "\n",
    "# adding layers to model\n",
    "model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=(3, 64, 64), activation='relu', strides=(1,1), data_format=\"channels_first\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(filters=16, kernel_size=(3,3), padding='same', activation='relu', strides=(1,1), data_format=\"channels_first\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "model.add(Convolution2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', strides=(1,1), data_format=\"channels_first\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1,1), activation='relu', data_format=\"channels_first\"))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1,1), activation='relu', data_format=\"channels_first\"))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6912))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(3072))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "model.add(Reshape([3,32, 32]))\n",
    "#model.add(UpSampling2D([2, 2], data_format=\"channels_first\"))\n",
    "model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1,1), activation='relu', data_format=\"channels_first\"))\n",
    "model.add(Convolution2D(filters=18, kernel_size=(5,5), padding='same', strides=(1,1), activation='relu', data_format=\"channels_first\"))\n",
    "model.add(Convolution2D(filters=32, kernel_size=(3, 3), padding='same', strides=(1,1), activation='relu', data_format=\"channels_first\"))\n",
    "model.add(Convolution2D(filters=16, kernel_size=(3,3), padding='same', strides=(1,1), activation='relu', data_format=\"channels_first\"))\n",
    "#model.add(UpSampling2D([2,2]))\n",
    "model.add(Convolution2D(filters=3, kernel_size=(3,3), padding='same', strides=(1,1), activation='relu', data_format=\"channels_first\"))\n",
    " #do all calculations do see size of all inputs and outputs\n",
    "model.add(Reshape([3, 32, 32]))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "history= model.fit(X_train, y_train, batch_size=10, epochs=1, verbose=0, validation_data=(X_val, y_val))\n",
    "#model.save(cnn.h5)\n",
    "#print(history.history.keys())\n",
    "#plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "#plt.title('Accuracy')\n",
    "#plt.xlabel('epoch')\n",
    "#plt.legend(['train', 'test'], loc='upper_left')\n",
    "\n",
    "score=model.evaluate(X_val, y_val, verbose=0)\n",
    "print('Test Score:', score[0] )\n",
    "print('accuracy:', score[1])\n",
    "plt.show()\n",
    "\n",
    "ex=1\n",
    "\n",
    "ex_x_train = X_train[ ex *batch_size:( ex +1 ) *batch_size]\n",
    "ex_y_train = y_train[ ex *batch_size:( ex +1 ) *batch_size]\n",
    "ex_x_valid = X_valid[ ex *batch_size:( ex +1 ) *batch_size]\n",
    "ex_y_valid = y_valid[ ex *batch_size:( ex +1 ) *batch_size]\n",
    "    \n",
    "pred = model.predict(ex_x_train, ex_y_train)\n",
    "predv = model.predict(ex_x_valid, ex_y_valid)\n",
    "pred = squeeze(pred)\n",
    "predv = squeeze(predv)\n",
    "\n",
    "i=2\n",
    "draw_image(ex_x_train[i], ex_y_train[i], pred[i])\n",
    "draw_image(ex_x_valid[i], ex_y_valid[i], predv[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
